{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfKvWAVnz8OB",
    "tags": []
   },
   "source": [
    "# Derived from AUTOMATIC1111's Stable Diffusion WebUI \n",
    "\n",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RUN ALL CELLS BELOW AFTER MACHINE BOOT\n",
    "\n",
    "\n",
    "\n",
    "If you need to soft-restart the webui, just stop and start the final cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST CELL SETS UP THE ENVIRONMENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T01:53:22.433168Z",
     "iopub.status.busy": "2023-09-29T01:53:22.432848Z",
     "iopub.status.idle": "2023-09-29T01:56:37.596815Z",
     "shell.execute_reply": "2023-09-29T01:56:37.596038Z",
     "shell.execute_reply.started": "2023-09-29T01:53:22.433141Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Choose where to store your model checkpoints.\n",
    "\n",
    "# Free Tier\n",
    "# model_storage_dir = '/tmp/stable-diffusion-models'\n",
    "\n",
    "# Paid Tier\n",
    "model_storage_dir = '/storage/models'\n",
    "\n",
    "\n",
    "\n",
    "# Optional path settings\n",
    "repo_storage_dir = '/storage/stable-diffusion'         # Where to store your Stable Diffusion-related files.\n",
    "\n",
    "export_storage_dir = '/notebooks/exports'              # Where the generated images will be exported to.\n",
    "\n",
    "pip_cache_dir = None                                   # The installer can cache pip wheels so you don't have to re-download them\n",
    "                                                       # every time you start the machine. I recommed setting it to '/storage/pip/cache'\n",
    "\n",
    "\n",
    "# Other optional settings\n",
    "# You don't have to change these if you don't want to.\n",
    "\n",
    "symlink_to_notebooks = True                            # Enables the creation of symlinks back to /notebooks/\n",
    "\n",
    "activate_xformers = True                               # Enables the xformers optimizations using pre-built wheels.\n",
    "                                                       # Setting to True will automatically set up your environment/machine for xformers. \n",
    "\n",
    "link_novelai_anime_vae = True                          # Enables the linking of animevae.pt to each of the NovelAI models.\n",
    "                                                       # Set to True if you've downloaded both the NovelAI models and hypernetworks.\n",
    "\n",
    "activate_deepdanbooru = False                          # Enable and install DeepDanbooru -> https://github.com/KichangKim/DeepDanbooru\n",
    "\n",
    "activate_medvram = False                                # Enable medvram option.\n",
    "                                                       # These are model optimizations which will reduce VRAM usage at the expense of some speed.\n",
    "                                                       # Set to False if you have a lot of VRAM.\n",
    "\n",
    "disable_pickle_check = False                           # Disable the automatic check for unexpected data in model files.\n",
    "                                                       # Leave this set to False unless you have a reason to disable the check.\n",
    "\n",
    "gradio_port = False                                    # Launch Gradio on a specific port. Set to False to let Gradio choose a port.\n",
    "                                                       # This disables online Gradio app mode and you will only be able to access it on your local network.\n",
    "\n",
    "gradio_auth = False                                    # Enable gradio_auth and insecure-extension-access option.\n",
    "                                                       # Set to a username:password (for example: \"me:password\") to enable.\n",
    "\n",
    "search_paperspace_datasets = True                      # Enable searching for checkpoints in /datasets to link to the webui\n",
    "\n",
    "ui_theme = None                                        # Set the WEB UI theme. Values can be None (default) or 'dark'.\n",
    "\n",
    "insecure_extension_access = False                      # Force enable extensions without a password.\n",
    "                                                       # If you don't set a password anyone can install and run arbitrary code on your machine!\n",
    "                                                       # Instead, use gradio_auth which will automatically enable extensions when set.\n",
    "\n",
    "gradio_queue = False                                   # Uses gradio queue; experimental option; breaks restart UI button.\n",
    "\n",
    "install_pip_xformers = False                           # Install xformers through pip. Probably won't work because it needs Torch 2.0\n",
    "\n",
    "# ===================================================================================================\n",
    "# Save variables to Jupiter's temp storage so we can access it even if the kernel restarts.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir export_storage_dir activate_xformers link_novelai_anime_vae activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth search_paperspace_datasets ui_theme insecure_extension_access pip_cache_dir gradio_queue install_pip_xformers\n",
    "\n",
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru pip_cache_dir install_pip_xformers\n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, pip_cache_dir, install_pip_xformers]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade wheel setuptools\n",
    "\n",
    "if pip_cache_dir:\n",
    "    !pip install git+https://github.com/pixelb/crudini.git\n",
    "    !mkdir -p \"{pip_cache_dir}\"\n",
    "    !python3 -m crudini --set /etc/pip.conf global cache-dir \"{pip_cache_dir}\"\n",
    "    !echo \"Set pip cache directory: $(pip cache dir)\"\n",
    "\n",
    "# Uninstall PyTorch and some other libraries so the WebUI can install the versions it needs\n",
    "!pip uninstall -y torch torchvision torchaudio protobuf\n",
    "\n",
    "# Import launch.py which will automatically run the install script but not launch the WebUI.\n",
    "import launch\n",
    "launch.prepare_environment()\n",
    "\n",
    "# Install things for this notebook\n",
    "!pip install requests gdown bs4 markdownify\n",
    "\n",
    "# The installer isn't installing deepdanbooru right now so we'll do it manually.\n",
    "if activate_deepdanbooru:\n",
    "    # https://github.com/KichangKim/DeepDanbooru/releases\n",
    "    !pip install \"git+https://github.com/KichangKim/DeepDanbooru.git@v3-20211112-sgd-e28#egg=deepdanbooru[tensorflow]\" # $(curl --silent \"https://api.github.com/KichangKim/DeepDanbooru/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/')#egg=deepdanbooru[tensorflow]\" # tensorflow==2.10.0 tensorflow-io==0.27.0 flatbuffers==1.12\n",
    "\n",
    "# We need to install xformers first so that the WebUI installer can install the correct version of PyTorch afterwards\n",
    "if activate_xformers:\n",
    "    if install_pip_xformers:\n",
    "        print('Installing xformers through pip...')\n",
    "        !pip install --no-dependencies xformers\n",
    "    else:\n",
    "        import subprocess\n",
    "        from glob import glob\n",
    "        def download_release(url, binary_name='xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl'):\n",
    "            tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "            !wget \"{url}\" -O \"{tmp_dir}/{binary_name}\"\n",
    "            return os.path.join(tmp_dir, binary_name)\n",
    "\n",
    "        xformers_whl = None\n",
    "        found_xformers_whls = glob('/notebooks/xformers-*')\n",
    "        if len(found_xformers_whls) == 1:\n",
    "            print('Installing xformers using your pre-built wheel...')\n",
    "            xformers_whl = found_xformers_whls[0]\n",
    "            delete_whl = False\n",
    "        elif len(found_xformers_whls) > 1:\n",
    "            print('Found more than one Xformers wheel in /notebooks so not doing anything!')\n",
    "        else:\n",
    "            print('Installing xformers from wheels on Github...')\n",
    "            delete_whl = True\n",
    "            # Set up pip packages\n",
    "            # !pip uninstall -y torch  torchvision torchaudio # Remove existing pytorch install.\n",
    "            # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # Install pytorch for cuda 11.3\n",
    "            s = subprocess.getoutput('nvidia-smi')\n",
    "            if 'A4000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/raw/main/a4000/xformers-0.0.18%2Bda27862.d20230413-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A5000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A6000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'P5000' in s:\n",
    "                xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/p5000/xformers-0.0.16%2B6f3c20f.d20230127-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 4000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 5000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A100' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'M4000' in s:\n",
    "                print('xformers for M4000 hasn\\'t been built yet.')\n",
    "                # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            else:\n",
    "                print('GPU not matched to xformers binary so a one-size-fits-all binary was installed. If you have any issues, please build xformers using the Tools block below.')\n",
    "                xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "        if xformers_whl:\n",
    "            !pip uninstall -y xformers\n",
    "            # We're going to install xformers without installing any of its dependencies since they should already be installed.\n",
    "            # If you have any issues then replacing --no-dependencies with --force-reinstall\n",
    "            !pip install --no-dependencies \"{xformers_whl}\"\n",
    "            if delete_whl:\n",
    "                !rm -rf \"{xformers_whl}\"\n",
    "# Make sure important directories exists\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{model_storage_dir}/vae\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/VAE\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/Lora\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/log/images\"\n",
    "\n",
    "!echo -e \"\\n===================================\\nDone! If you're seeing this the process has exited successfully.\\n\"\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "#######################    REQUIRED FIXUPS\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "!pip install --upgrade \"tensorflow\"\n",
    "!pip install \"tensorboardX\"\n",
    "!pip install --upgrade \"xformers==0.0.20\" \"protobuf==3.20.3\"\n",
    "!pip install --upgrade \"pydantic<2>1.12\" \"spacy>3.4<4\" \"fastapi-class\"\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir link_novelai_anime_vae search_paperspace_datasets\n",
    "    test = [model_storage_dir, repo_storage_dir, link_novelai_anime_vae, search_paperspace_datasets]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "model_storage_dir = Path(model_storage_dir)\n",
    "\n",
    "if not model_storage_dir.exists():\n",
    "    print('Your model storage directory does not exist:', model_storage_dir)\n",
    "    sys.exit(1)\n",
    "\n",
    "webui_root_model_path = Path(repo_storage_dir, 'stable-diffusion-webui/models')\n",
    "webui_sd_model_path = Path(webui_root_model_path, 'Stable-diffusion')\n",
    "webui_hypernetwork_path = Path(webui_root_model_path, 'hypernetworks')\n",
    "webui_vae_path = Path(webui_root_model_path, 'VAE')\n",
    "webui_lora_model_path = Path(webui_root_model_path, 'Lora')\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    deleted = False\n",
    "    dir = Path(dir)\n",
    "    for file in dir.iterdir():\n",
    "        if file.is_symlink() and not file.exists():\n",
    "            print('Symlink broken, removing:', file)\n",
    "            file.unlink()\n",
    "            deleted = True\n",
    "    if deleted:\n",
    "        print('')\n",
    "\n",
    "def create_symlink(source, dest):\n",
    "    if os.path.isdir(dest):\n",
    "        dest = Path(dest, os.path.basename(source))\n",
    "    if not dest.exists():\n",
    "        os.symlink(source, dest)\n",
    "    print(source, '->', Path(dest).absolute())\n",
    "\n",
    "# Check for broken symlinks and remove them\n",
    "print('Removing broken symlinks...')\n",
    "delete_broken_symlinks(webui_sd_model_path)\n",
    "delete_broken_symlinks(webui_hypernetwork_path)\n",
    "delete_broken_symlinks(webui_vae_path)\n",
    "delete_broken_symlinks(webui_lora_model_path)\n",
    "\n",
    "def link_ckpts(source_path):\n",
    "    # Link .ckpt and .safetensor/.st files (recursive)\n",
    "    print('\\nLinking .ckpt and .safetensor/.safetensors/.st files in', source_path)\n",
    "    source_path = Path(source_path)\n",
    "    for file in [p for p in source_path.rglob('*') if p.suffix in ['.ckpt', '.safetensor', '.safetensors', '.st']]:\n",
    "        if Path(file).parent.parts[-1] not in ['hypernetworks', 'vae'] :\n",
    "            if not (webui_sd_model_path / file.name):\n",
    "                print('New model:', file.name)\n",
    "            create_symlink(file, webui_sd_model_path)\n",
    "    # Link config yaml files\n",
    "    print('\\nLinking config .yaml files in', source_path)\n",
    "    for file in model_storage_dir.glob('*.yaml'):\n",
    "        create_symlink(file, webui_sd_model_path)\n",
    "\n",
    "\n",
    "link_ckpts(model_storage_dir)\n",
    "\n",
    "# Link hypernetworks\n",
    "print('\\nLinking hypernetworks...')\n",
    "hypernetwork_source_path = Path(model_storage_dir, 'hypernetworks')\n",
    "if hypernetwork_source_path.is_dir():\n",
    "    for file in hypernetwork_source_path.iterdir():\n",
    "        create_symlink(hypernetwork_source_path / file, webui_hypernetwork_path)\n",
    "else:\n",
    "    print('Hypernetwork storage directory not found:', hypernetwork_source_path)\n",
    "\n",
    "# Link VAEs\n",
    "print('\\nLinking VAEs...')\n",
    "vae_source_path = Path(model_storage_dir, 'vae')\n",
    "if vae_source_path.is_dir():\n",
    "    for file in vae_source_path.iterdir():\n",
    "        create_symlink(vae_source_path / file, webui_vae_path)\n",
    "else:\n",
    "    print('VAE storage directory not found:', vae_source_path)\n",
    "\n",
    "# Link Lora\n",
    "print('\\nLinking Loras...')\n",
    "lora_source_path = Path(model_storage_dir, 'Lora')\n",
    "if lora_source_path.is_dir():\n",
    "    for file in lora_source_path.iterdir():\n",
    "        create_symlink(lora_source_path / file, webui_lora_model_path)\n",
    "else:\n",
    "    print('Lora storage directory not found:', lora_source_path)\n",
    "\n",
    "# Link the NovelAI files for each of the NovelAI models\n",
    "print('\\nLinking NovelAI files for each of the NovelAI models...')\n",
    "for model in model_storage_dir.glob('novelai-*.ckpt'):\n",
    "    yaml = model.stem + '.yaml'\n",
    "    if os.path.exists(yaml):\n",
    "        print('New NovelAI model config:', yaml)\n",
    "        create_symlink(yaml, webui_sd_model_path)\n",
    "\n",
    "if link_novelai_anime_vae:\n",
    "    print('\\nLinking NovelAI anime VAE...')\n",
    "    for model in model_storage_dir.glob('novelai-*.ckpt'):\n",
    "        if (model_storage_dir / 'hypernetworks' / 'animevae.pt').is_file():\n",
    "            vae = model.stem + '.vae.pt'\n",
    "            if not os.path.exists(webui_vae_path):\n",
    "                print(f'Linking NovelAI {vae} and {model}')\n",
    "            create_symlink(model_storage_dir / 'hypernetworks' / 'animevae.pt', webui_vae_path)\n",
    "        else:\n",
    "            print(f'{model_storage_dir}/hypernetworks/animevae.pt not found!')\n",
    "\n",
    "if search_paperspace_datasets:\n",
    "    if Path('/datasets').is_dir():\n",
    "        link_ckpts('/datasets')\n",
    "    else:\n",
    "        print('\\nNo datasets mounted!')\n",
    "        \n",
    "!sudo apt-get install -y libxext-dev libx11-dev x11proto-gl-dev libtool xvfb libtool-bin libosmesa6-dev libgles2-mesa-dev libegl1-mesa-dev\n",
    "!pip install pegl pyrender\n",
    "%cd /notebooks/libglvnd\n",
    "!make install\n",
    "!ldconfig -N -v | grep libEGL\n",
    "!python -c 'import pyrender; from pyrender.platforms import egl; from OpenGL.EGL import *; devices = egl.query_devices(); print(devices)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND CELL BACKGROUND AN X FRAMEBUFFER\n",
    "\n",
    "re-run only if X crashes\n",
    "\n",
    "Without an active FB vispy throws a shit fit\n",
    "\n",
    "Mesa EGL is used to render\n",
    "\n",
    "TODO Force NVIDIA EGL binding somehow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T02:25:37.877593Z",
     "iopub.status.busy": "2023-09-29T02:25:37.876950Z",
     "iopub.status.idle": "2023-09-29T02:25:37.882925Z",
     "shell.execute_reply": "2023-09-29T02:25:37.881984Z",
     "shell.execute_reply.started": "2023-09-29T02:25:37.877563Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import shlex\n",
    "p = Popen(shlex.split('/usr/bin/Xvfb :0 -screen 0 1024x768x24 -ac +extension GLX +render -noreset'), bufsize=1, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CELL STARTS WEBUI\n",
    "\n",
    "RE-RUN ONLY THIS CELL TO RESTART WEBUI IF NEEDED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T02:25:52.849790Z",
     "iopub.status.busy": "2023-09-29T02:25:52.849538Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "!export DISPLAY=:0\n",
    "!export MESA_GL_VERSION_OVERRIDE=3.3\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['DISPLAY']= ':0'\n",
    "os.environ['MESA_GL_VERSION_OVERRIDE']= '3.3'\n",
    "\n",
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth ui_theme insecure_extension_access gradio_queue\n",
    "    test = [model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, activate_medvram, disable_pickle_check, gradio_port, gradio_auth, ui_theme, insecure_extension_access, gradio_queue]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "insecure_extension_access = True\n",
    "# Code to set the options you want as defined in the very first block\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else ''\n",
    "theme = f'--theme {ui_theme}' if ui_theme else ''\n",
    "insecure_extension_access = '--enable-insecure-extension-access' if insecure_extension_access else ''\n",
    "queue = '--gradio-queue' if gradio_queue else ''\n",
    "\n",
    "# Launch args go below:\n",
    "!python -c \"import vispy; print(vispy.sys_info())\"\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} {theme} {queue} {insecure_extension_access}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
